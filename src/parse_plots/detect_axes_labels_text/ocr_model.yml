number: '0123456789'
symbol: "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ â‚¬"
lang_char: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'
experiment_name: 'finetune'
train_data: '/allen/aibs/informatics/aamster/benetech-making-graphs-accessible/ocr_train_images/'
valid_data: '/allen/aibs/informatics/aamster/benetech-making-graphs-accessible/ocr_train_images/val'
manualSeed: 1111
workers: 6
batch_size: 32 #32
num_iter: 300000
valInterval: 20000
saved_model: '/allen/aibs/informatics/aamster/benetech-making-graphs-accessible/finetuned_ocr_model/finetune/best_accuracy.pth' #'saved_models/en_filtered/iter_300000.pth'
FT: False
optim: False # default is Adadelta
lr: 0.001
beta1: 0.9
rho: 0.95
eps: 0.00000001
grad_clip: 5
#Data processing
select_data: 'train' # this is dataset folder in train_data
batch_ratio: '1'
total_data_usage_ratio: 1.0
batch_max_length: 34
imgH: 32
imgW: 100
rgb: False
contrast_adjust: False
sensitive: True
PAD: True
contrast_adjust: 0.0
data_filtering_off: False
# Model Architecture
Transformation: 'None'
FeatureExtraction: 'VGG'
SequenceModeling: 'BiLSTM'
Prediction: 'CTC'
num_fiducial: 20
input_channel: 1
output_channel: 256
hidden_size: 256
decode: 'greedy'
new_prediction: False
freeze_FeatureFxtraction: False
freeze_SequenceModeling: False
model_dir: '/allen/aibs/informatics/aamster/benetech-making-graphs-accessible/finetuned_ocr_model'